{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "- 使用 GRU、LSTM 计算字符级别语言困惑度  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实语言困惑度就是对RNN模型在训练过程中求出的损失值的指数形式（也即交叉熵的指数值），由于不要求输出对应的样例，所以就只在训练过程中输出对应的困惑度的值；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T16:46:44.411962Z",
     "start_time": "2019-06-10T16:46:44.383894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 16647\n",
      "total chars: 2514\n"
     ]
    }
   ],
   "source": [
    "# 根据给定 txt 建立语料库\n",
    "path = './poetryFromTang.txt'\n",
    "text = open(path,'rb').read().lower().decode('utf-8')\n",
    "print ('corpus length:', len(text))\n",
    "#print(type(text))\n",
    "chars = set(text)\n",
    "#print(chars[0:10])\n",
    "print ('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T16:46:44.425931Z",
     "start_time": "2019-06-10T16:46:44.415953Z"
    }
   },
   "outputs": [],
   "source": [
    "# 对训练集进行处理\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "# 判断下一个字符的信息\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i : i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T17:15:44.152336Z",
     "start_time": "2019-06-10T17:15:44.144334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T18:24:27.276975Z",
     "start_time": "2019-06-10T18:24:27.184210Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = []\n",
    "y = []\n",
    "for i ,sentence in enumerate(sentences):\n",
    "    x = []\n",
    "    for _ , char in enumerate(sentence):\n",
    "        x.append(char_indices[char])\n",
    "    X.append(x)\n",
    "    y.append(char_indices[next_chars[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T18:24:31.868927Z",
     "start_time": "2019-06-10T18:24:31.856960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[644, 1980, 1544, 2073, 1373, 154, 2254, 406, 762, 2401, 1048, 1549, 435, 513, 1730, 1552, 126, 622, 1544, 619, 2053, 2347, 105, 2089, 834, 1763, 1674, 1048, 2228, 958, 2197, 1259, 1875, 2033, 1905, 1544, 2406, 311, 1667, 2504]\n",
      "311\n"
     ]
    }
   ],
   "source": [
    "print((X[2]))\n",
    "print(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T18:10:05.765929Z",
     "start_time": "2019-06-10T18:10:05.745983Z"
    }
   },
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "# 创建 RNN + GRU 类\n",
    "import torch.nn as nn\n",
    "\n",
    "class BaseGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0, bidirectional=False):\n",
    "        super(BaseGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.embedding = nn.Embedding(2514, 300)\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.h2o = nn.Linear(self.num_directions * hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)  \n",
    "    def forward(self, inputs):\n",
    "        hidden = self.initHidden(False)\n",
    "        line = self.embedding(inputs)\n",
    "        line = torch.transpose(line, 0, 1)\n",
    "        output, hidden = self.gru(line, hidden)\n",
    "        output = self.h2o(output[line.size(0)-1])\n",
    "        output = self.softmax(output)\n",
    "        return output    \n",
    "    def initHidden(self, is_cuda=True):\n",
    "        if is_cuda:\n",
    "            hidden = torch.zeros(self.num_layers*self.num_directions, 1, self.hidden_size).cuda()\n",
    "        else:\n",
    "            hidden = torch.zeros(self.num_layers*self.num_directions, 1, self.hidden_size)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T18:26:30.261886Z",
     "start_time": "2019-06-10T18:26:06.394908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity:2645.736828925497\n",
      "perplexity:2951.3793151299483\n",
      "perplexity:2509.8388895133567\n",
      "perplexity:3018.1107104001226\n",
      "perplexity:2477.552070313373\n",
      "perplexity:1952.6048012003296\n",
      "perplexity:2628.1760619370925\n",
      "perplexity:3072.370747280244\n",
      "perplexity:2725.3983313229996\n",
      "perplexity:2806.180224461259\n",
      "perplexity:2420.739026827909\n",
      "perplexity:2888.0025117170517\n",
      "perplexity:2344.9632858738937\n",
      "perplexity:2738.640539417584\n",
      "perplexity:2012.0085305711323\n",
      "perplexity:2679.4806241140277\n",
      "perplexity:2771.5134421120947\n",
      "perplexity:2085.6913129180034\n",
      "perplexity:2744.46967799424\n",
      "perplexity:2220.997818287951\n",
      "perplexity:2363.733741537051\n",
      "perplexity:3000.566883377853\n",
      "perplexity:2295.051606359756\n",
      "perplexity:3024.983256069884\n",
      "perplexity:2453.5463465641287\n",
      "perplexity:2263.5873865196995\n",
      "perplexity:1536.1524081058724\n",
      "perplexity:2774.6049737495887\n",
      "perplexity:2577.306895368079\n",
      "perplexity:2052.5402243587655\n",
      "perplexity:1936.9772064227448\n",
      "perplexity:3067.8881276763705\n",
      "perplexity:2198.387449320412\n",
      "perplexity:2352.44790607058\n",
      "perplexity:2603.700218639746\n",
      "perplexity:3225.2811569638634\n",
      "perplexity:1919.3987141229893\n",
      "perplexity:2382.7873787644216\n",
      "perplexity:2856.845371387727\n",
      "perplexity:2593.767021934093\n",
      "perplexity:1556.8829291650454\n",
      "perplexity:2318.2360660855525\n",
      "perplexity:2694.3144658005385\n",
      "perplexity:714.7472459047946\n",
      "perplexity:2699.97200934136\n",
      "perplexity:2329.592145360928\n",
      "perplexity:2685.3093237440444\n",
      "perplexity:2041.3876935271412\n",
      "perplexity:2992.799225162278\n",
      "perplexity:642.7678364910889\n",
      "perplexity:1708.8050995115198\n",
      "perplexity:2136.2559842337364\n",
      "perplexity:1357.1101538987243\n",
      "perplexity:2063.3659949041144\n",
      "perplexity:2884.257833649759\n",
      "perplexity:3087.815594346629\n",
      "perplexity:2454.112663872199\n",
      "perplexity:2109.9105358507904\n",
      "perplexity:2338.950803324895\n",
      "perplexity:1817.5127561641507\n",
      "perplexity:1481.939422892002\n",
      "perplexity:2862.8168965731065\n",
      "perplexity:2292.62339954355\n",
      "perplexity:1966.1080983788963\n",
      "perplexity:2391.754067577999\n",
      "perplexity:2719.329602744714\n",
      "perplexity:2166.16924345245\n",
      "perplexity:2463.8857902732316\n",
      "perplexity:2343.220713442724\n",
      "perplexity:2864.555193188324\n",
      "perplexity:2419.7049964431594\n",
      "perplexity:1667.5961404150235\n",
      "perplexity:2831.615501612754\n",
      "perplexity:2218.878603295194\n",
      "perplexity:126.7294936904072\n",
      "perplexity:3115.7397346964403\n",
      "perplexity:2204.599889281468\n",
      "perplexity:1957.5205345456156\n",
      "perplexity:2344.469108744446\n",
      "perplexity:2731.4636714080716\n",
      "perplexity:38.8799553170024\n",
      "perplexity:2493.1836956376874\n",
      "perplexity:2084.961451873571\n",
      "perplexity:2902.1496410583354\n",
      "perplexity:3088.643185721414\n",
      "perplexity:2760.5609013981148\n",
      "perplexity:2846.2110557489177\n",
      "perplexity:3889.1741382867503\n",
      "perplexity:1109.9774452638555\n",
      "perplexity:2529.5117382156873\n",
      "perplexity:2335.595048677039\n",
      "perplexity:2062.4531473609827\n",
      "perplexity:2657.7414754719252\n",
      "perplexity:1857.8681681552043\n",
      "perplexity:2301.3835712473974\n",
      "perplexity:2947.968518749161\n",
      "perplexity:1079.037511721579\n",
      "perplexity:2241.7809631802643\n",
      "perplexity:2826.4596623385537\n",
      "perplexity:3210.3272274366254\n"
     ]
    }
   ],
   "source": [
    "# 创建模型并进行训练\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torch\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.05\n",
    "n_hidden = 128\n",
    "model = BaseGRU(300, n_hidden,len(chars), 2, 0.5, bidirectional=True)\n",
    "def train(model, category_tensor, line_tensor, weight_clip=0.1):\n",
    "    output = model(line_tensor)\n",
    "    model.zero_grad()\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    for p in model.parameters():\n",
    "        if hasattr(p.grad, \"data\"):\n",
    "            p.data.add_(-learning_rate, p.grad.data)\n",
    "    return output, loss.item()\n",
    "for iter in range(0,1):\n",
    "    for i in range(0,100):\n",
    "        Y = torch.tensor([y[i]], dtype=torch.long)\n",
    "        x = torch.tensor([X[i]], dtype=torch.long)\n",
    "        _, loss = train(model,Y,x)\n",
    "        print('perplexity:{}'.format(math.exp(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
